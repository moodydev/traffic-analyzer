{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------------------------------\n",
      "(ID: 0, Load index: 0)\n",
      "(ID: 1, Load index: 0)\n",
      "(ID: 2, Load index: 0)\n",
      "(ID: 3, Load index: 0)\n",
      "(ID: 4, Load index: 0)\n",
      "(ID: 5, Load index: 0)\n",
      "(ID: 6, Load index: 0)\n",
      "(ID: 7, Load index: 0)\n",
      "(ID: 8, Load index: 0)\n",
      "(ID: 9, Load index: 0)\n",
      "=================================================================================================================\n",
      "Worker(ID: 1 Load index: 0, Devices: [(ID: 0, Load index: 0), (ID: 8, Load index: 0), (ID: 2, Load index: 0), (ID: 4, Load index: 0), (ID: 6, Load index: 0)])\n",
      "Worker(ID: 2 Load index: 0, Devices: [(ID: 1, Load index: 0), (ID: 3, Load index: 0), (ID: 5, Load index: 0), (ID: 9, Load index: 0), (ID: 7, Load index: 0)])\n",
      "Total msgs: 33\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "(ID: 0, Load index: 0.08709)\n",
      "(ID: 1, Load index: 0)\n",
      "(ID: 2, Load index: 0.11495)\n",
      "(ID: 3, Load index: 0)\n",
      "(ID: 4, Load index: 0.01594)\n",
      "(ID: 5, Load index: 0.07236)\n",
      "(ID: 6, Load index: 0.19955)\n",
      "(ID: 7, Load index: 0.15728)\n",
      "(ID: 8, Load index: 0.29826)\n",
      "(ID: 9, Load index: 0.06246)\n",
      "=================================================================================================================\n",
      "Worker(ID: 1 Load index: 0.51375, Devices: [(ID: 8, Load index: 0.29826), (ID: 6, Load index: 0.19955), (ID: 4, Load index: 0.01594)])\n",
      "Worker(ID: 2 Load index: 0.49414, Devices: [(ID: 7, Load index: 0.15728), (ID: 2, Load index: 0.11495), (ID: 0, Load index: 0.08709), (ID: 5, Load index: 0.07236), (ID: 9, Load index: 0.06246), (ID: 1, Load index: 0), (ID: 3, Load index: 0)])\n",
      "Total msgs: 46\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "(ID: 0, Load index: 0.10041)\n",
      "(ID: 1, Load index: 0.07192)\n",
      "(ID: 2, Load index: 0.0986)\n",
      "(ID: 3, Load index: 0.09716)\n",
      "(ID: 4, Load index: 0.05573)\n",
      "(ID: 5, Load index: 0.0429)\n",
      "(ID: 6, Load index: 0.19144)\n",
      "(ID: 7, Load index: 0.09874)\n",
      "(ID: 8, Load index: 0.24216)\n",
      "(ID: 9, Load index: 0.0092)\n",
      "=================================================================================================================\n",
      "Worker(ID: 1 Load index: 0.48933, Devices: [(ID: 8, Load index: 0.24216), (ID: 6, Load index: 0.19144), (ID: 4, Load index: 0.05573)])\n",
      "Worker(ID: 2 Load index: 0.51893, Devices: [(ID: 0, Load index: 0.10041), (ID: 7, Load index: 0.09874), (ID: 2, Load index: 0.0986), (ID: 3, Load index: 0.09716), (ID: 1, Load index: 0.07192), (ID: 5, Load index: 0.0429), (ID: 9, Load index: 0.0092)])\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import uuid\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from math import ceil, sqrt\n",
    "from pprint import pprint\n",
    "from random import choice, gauss, seed\n",
    "from statistics import stdev\n",
    "\n",
    "\n",
    "##########\n",
    "# Entities\n",
    "##########\n",
    "\n",
    "class Worker:\n",
    "    def __init__(self, identity=None):\n",
    "        self.identity = identity or uuid.uuid1().hex\n",
    "        self.devices = set()\n",
    "        self.databases = set()\n",
    "        self.load_index = 0\n",
    "     \n",
    "    def __repr__(self):\n",
    "        return 'Worker(ID: {} Load index: {}, Devices: {})'.format(\n",
    "            self.identity, self.load_index, sorted(self.devices, reverse=True))\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        if self.load_index == other.load_index:\n",
    "            return len(self.devices) < len(other.devices)\n",
    "        else:\n",
    "            return self.load_index < other.load_index\n",
    "    \n",
    "    def __contains__(self, device):\n",
    "        return device in self.devices\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.devices)\n",
    "    \n",
    "    \n",
    "class Device:\n",
    "    def __init__(self, id_, load_index=0):\n",
    "        self.id_ = id_\n",
    "        self.load_index = load_index\n",
    "        # TODO reprocessing will be memory hog, need mechanism for effective dealing with this\n",
    "        # some out of order data is ok, since scheduler will just reasign properly\n",
    "        # good idea would be to increase memory treshold on those workers, and decrease on others\n",
    "        # someone should suggest this good idea (because it really rocks)\n",
    "        self.reprocessing = False\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return '(ID: {id_}, Load index: {load_index})'.format(**self.__dict__)\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.load_index < other.load_index\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return self.id_ == other.id_\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(self.id_)\n",
    "\n",
    "    \n",
    "class Database:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.devices = set()\n",
    "        self.load_index = 0\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return 'DB(Name: {name}, Load Index)'.format(**self.__dict__)\n",
    "\n",
    "    \n",
    "##########\n",
    "# Settings\n",
    "##########\n",
    "\n",
    "_statistics = defaultdict(Counter)  # Redis simulator\n",
    "_device_num = 10  # device count\n",
    "_worker_num = 2  # worker count\n",
    "_devices = [Device(i) for i in range(_device_num)]\n",
    "_workers = [Worker(i+1) for i in range(_worker_num)]\n",
    "int_time = 10  # interval in which we should collect\n",
    "\n",
    "decimal_points = len([c for c in str(_device_num)])\n",
    "decimal_points = ceil(decimal_points + (decimal_points*5/4))\n",
    "\n",
    "device_load = round((1/_device_num), decimal_points)  # average load time per worker\n",
    "gauss_deviation =device_load * sqrt(_device_num)  # deviation per load\n",
    "worker_deviation = 0.1  # index 1 how much % more load worker can have to preserve devices\n",
    "\n",
    "load_per_worker = round((1/_worker_num), decimal_points)  # load per worker, index 1 \n",
    "deviation_per_worker_load = load_per_worker+(load_per_worker*worker_deviation)  # load with deviation\n",
    "\n",
    "\n",
    "###########\n",
    "# Calculate\n",
    "###########\n",
    "\n",
    "def load_simulator():\n",
    "    device = choice(_devices)\n",
    "    calc_time = abs(round(gauss(device_load, gauss_deviation), 5))\n",
    "    _statistics[device]['count'] += 1\n",
    "    _statistics[device]['calc_time'] += calc_time \n",
    "    return calc_time\n",
    "\n",
    "def generate_data(seed_num):\n",
    "    seed(seed_num)\n",
    "    total_messages = 0\n",
    "    global _statistics\n",
    "    del _statistics\n",
    "    _statistics = defaultdict(Counter)  # Redis simulator\n",
    "    sleep_time = 0\n",
    "    while sleep_time < int_time:\n",
    "        total_messages += 1\n",
    "        sleep_time += load_simulator()\n",
    "        \n",
    "    \n",
    "    return total_messages\n",
    "\n",
    "def _load_index(int_time, system_msgs, device_calc, device_msgs):\n",
    "    calc_time_index = .7\n",
    "    count_index = 0.3    \n",
    "    return round((device_calc*calc_time_index/int_time +\n",
    "            device_msgs*count_index/system_msgs)/(calc_time_index + count_index), decimal_points)\n",
    "\n",
    "\n",
    "def run_analytics(total_messages):\n",
    "    print('Total msgs:', total_messages)\n",
    "    for device, value in _statistics.items():\n",
    "        # TODO need exception handling here for ZeroDivisionError\n",
    "        proc_time = value['calc_time']/value['count']\n",
    "        load_index = _load_index(int_time, total_messages, value['calc_time'], value['count'])\n",
    "        device.load_index = load_index\n",
    "#         print('Device(id: {}, proc_time: {}, count: {}, load_index: {})'.format(\n",
    "#                 device, proc_time, value['count'], load_index))     \n",
    "\n",
    "\n",
    "def sort_devices(devices, workers, load_per_worker, deviation_per_worker_load):\n",
    "    for worker in sorted(workers, reverse=True):\n",
    "        worker_new_devices = set()\n",
    "        worker.load_index = 0\n",
    "        for device in sorted(devices, reverse=True):\n",
    "            if device in worker:\n",
    "                if (device.load_index + worker.load_index) < deviation_per_worker_load:\n",
    "                    worker_new_devices.add(device)\n",
    "                    worker.load_index += device.load_index\n",
    "        devices -= worker_new_devices\n",
    "        worker.devices = worker_new_devices\n",
    "    \n",
    "    # TODO: This part needs to be smarter, not just random \n",
    "    # Heavy workers(like device or two with heavy load) shouldn't get small load devices\n",
    "    # One worker should always be elected as 'reprocessing' worker which would just deal with \n",
    "    # devices that are in reprocess state\n",
    "    \n",
    "    # existing coord service works great with this! victory!\n",
    "    for device in sorted(devices, reverse=True):\n",
    "        worker = sorted(workers)[0]\n",
    "        worker.devices.add(device)\n",
    "        worker.load_index += device.load_index\n",
    "    \n",
    "    return workers    \n",
    "    \n",
    "def _print_devices():\n",
    "    print('-'*113)\n",
    "    for device in _devices:\n",
    "        print(device)\n",
    "    \n",
    "def _print_workers(workers):\n",
    "    print('='*113)\n",
    "    for worker in workers:\n",
    "        print(worker)\n",
    "    \n",
    "#####################\n",
    "# Ride the unicorn 🦄\n",
    "#####################\n",
    "\n",
    "def main():\n",
    "    _print_devices()\n",
    "    _workers_1 = sort_devices(set(_devices), _workers, load_per_worker, deviation_per_worker_load)\n",
    "    _print_workers(_workers_1)\n",
    "    msg_count = generate_data(2)\n",
    "    run_analytics(msg_count)\n",
    "    _print_devices()\n",
    "    _workers_2 = sort_devices(set(_devices), _workers_1, load_per_worker, deviation_per_worker_load)\n",
    "    _print_workers(_workers_2)\n",
    "    msg_count = generate_data(8)\n",
    "    run_analytics(msg_count)\n",
    "    _print_devices()\n",
    "    _workers_3 = sort_devices(set(_devices), _workers_2, load_per_worker, deviation_per_worker_load)\n",
    "    _print_workers(_workers_3)\n",
    "\n",
    "    \n",
    "main()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def test(*args):\n",
    "    print (len(args))\n",
    "    \n",
    "a = 5-3 > 1\n",
    "\n",
    "print(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
